{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查询package里的函数以及函数如何使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Any',\n",
       " 'BFloat16Storage',\n",
       " 'BFloat16Tensor',\n",
       " 'BoolStorage',\n",
       " 'BoolTensor',\n",
       " 'ByteStorage',\n",
       " 'ByteTensor',\n",
       " 'CUDAGraph',\n",
       " 'CUDAPluggableAllocator',\n",
       " 'Callable',\n",
       " 'CharStorage',\n",
       " 'CharTensor',\n",
       " 'ComplexDoubleStorage',\n",
       " 'ComplexFloatStorage',\n",
       " 'CudaError',\n",
       " 'DeferredCudaCallError',\n",
       " 'Device',\n",
       " 'DoubleStorage',\n",
       " 'DoubleTensor',\n",
       " 'Event',\n",
       " 'ExternalStream',\n",
       " 'FloatStorage',\n",
       " 'FloatTensor',\n",
       " 'HalfStorage',\n",
       " 'HalfTensor',\n",
       " 'IntStorage',\n",
       " 'IntTensor',\n",
       " 'List',\n",
       " 'LongStorage',\n",
       " 'LongTensor',\n",
       " 'MemPool',\n",
       " 'MemPoolContext',\n",
       " 'Optional',\n",
       " 'OutOfMemoryError',\n",
       " 'ShortStorage',\n",
       " 'ShortTensor',\n",
       " 'Stream',\n",
       " 'StreamContext',\n",
       " 'Tuple',\n",
       " 'Union',\n",
       " '_CudaBase',\n",
       " '_CudaDeviceProperties',\n",
       " '_DeviceGuard',\n",
       " '_HAS_PYNVML',\n",
       " '_LazySeedTracker',\n",
       " '_PYNVML_ERR',\n",
       " '_WrappedTritonKernel',\n",
       " '__all__',\n",
       " '__annotations__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_cached_device_count',\n",
       " '_check_bf16_tensor_supported',\n",
       " '_check_capability',\n",
       " '_check_cubins',\n",
       " '_cudart',\n",
       " '_device',\n",
       " '_device_count_amdsmi',\n",
       " '_device_count_nvml',\n",
       " '_device_t',\n",
       " '_dummy_type',\n",
       " '_exchange_device',\n",
       " '_extract_arch_version',\n",
       " '_get_amdsmi_clock_rate',\n",
       " '_get_amdsmi_device_index',\n",
       " '_get_amdsmi_device_memory_used',\n",
       " '_get_amdsmi_handler',\n",
       " '_get_amdsmi_memory_usage',\n",
       " '_get_amdsmi_power_draw',\n",
       " '_get_amdsmi_temperature',\n",
       " '_get_amdsmi_utilization',\n",
       " '_get_device',\n",
       " '_get_device_index',\n",
       " '_get_generator',\n",
       " '_get_nvml_device_index',\n",
       " '_get_pynvml_handler',\n",
       " '_get_rng_state_offset',\n",
       " '_initialization_lock',\n",
       " '_initialized',\n",
       " '_is_compiled',\n",
       " '_is_in_bad_fork',\n",
       " '_lazy_call',\n",
       " '_lazy_init',\n",
       " '_lazy_new',\n",
       " '_lazy_seed_tracker',\n",
       " '_maybe_exchange_device',\n",
       " '_memory_viz',\n",
       " '_nvml_based_avail',\n",
       " '_parse_visible_devices',\n",
       " '_queued_calls',\n",
       " '_raw_device_count_amdsmi',\n",
       " '_raw_device_count_nvml',\n",
       " '_raw_device_uuid_amdsmi',\n",
       " '_raw_device_uuid_nvml',\n",
       " '_register_triton_kernels',\n",
       " '_set_rng_state_offset',\n",
       " '_set_stream_by_id',\n",
       " '_sleep',\n",
       " '_tls',\n",
       " '_transform_uuid_to_ordinals',\n",
       " '_utils',\n",
       " '_warn_typed_storage_removal',\n",
       " 'amp',\n",
       " 'caching_allocator_alloc',\n",
       " 'caching_allocator_delete',\n",
       " 'caching_allocator_enable',\n",
       " 'can_device_access_peer',\n",
       " 'cast',\n",
       " 'change_current_allocator',\n",
       " 'check_error',\n",
       " 'classproperty',\n",
       " 'clock_rate',\n",
       " 'cudaStatus',\n",
       " 'cudart',\n",
       " 'current_blas_handle',\n",
       " 'current_device',\n",
       " 'current_stream',\n",
       " 'default_generators',\n",
       " 'default_stream',\n",
       " 'device',\n",
       " 'device_count',\n",
       " 'device_memory_used',\n",
       " 'device_of',\n",
       " 'empty_cache',\n",
       " 'gds',\n",
       " 'get_allocator_backend',\n",
       " 'get_arch_list',\n",
       " 'get_device_capability',\n",
       " 'get_device_name',\n",
       " 'get_device_properties',\n",
       " 'get_gencode_flags',\n",
       " 'get_per_process_memory_fraction',\n",
       " 'get_rng_state',\n",
       " 'get_rng_state_all',\n",
       " 'get_sync_debug_mode',\n",
       " 'graph',\n",
       " 'graph_pool_handle',\n",
       " 'graphs',\n",
       " 'has_half',\n",
       " 'has_magma',\n",
       " 'importlib',\n",
       " 'init',\n",
       " 'initial_seed',\n",
       " 'ipc_collect',\n",
       " 'is_available',\n",
       " 'is_bf16_supported',\n",
       " 'is_current_stream_capturing',\n",
       " 'is_initialized',\n",
       " 'jiterator',\n",
       " 'list_gpu_processes',\n",
       " 'lru_cache',\n",
       " 'make_graphed_callables',\n",
       " 'manual_seed',\n",
       " 'manual_seed_all',\n",
       " 'max_memory_allocated',\n",
       " 'max_memory_cached',\n",
       " 'max_memory_reserved',\n",
       " 'mem_get_info',\n",
       " 'memory',\n",
       " 'memory_allocated',\n",
       " 'memory_cached',\n",
       " 'memory_reserved',\n",
       " 'memory_snapshot',\n",
       " 'memory_stats',\n",
       " 'memory_stats_as_nested_dict',\n",
       " 'memory_summary',\n",
       " 'memory_usage',\n",
       " 'nccl',\n",
       " 'nvtx',\n",
       " 'os',\n",
       " 'power_draw',\n",
       " 'profiler',\n",
       " 'random',\n",
       " 'reset_accumulated_memory_stats',\n",
       " 'reset_max_memory_allocated',\n",
       " 'reset_max_memory_cached',\n",
       " 'reset_peak_memory_stats',\n",
       " 'seed',\n",
       " 'seed_all',\n",
       " 'set_device',\n",
       " 'set_per_process_memory_fraction',\n",
       " 'set_rng_state',\n",
       " 'set_rng_state_all',\n",
       " 'set_stream',\n",
       " 'set_sync_debug_mode',\n",
       " 'sparse',\n",
       " 'stream',\n",
       " 'streams',\n",
       " 'synchronize',\n",
       " 'temperature',\n",
       " 'threading',\n",
       " 'torch',\n",
       " 'traceback',\n",
       " 'tunable',\n",
       " 'use_mem_pool',\n",
       " 'utilization',\n",
       " 'warnings']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(torch.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function is_available in module torch.cuda:\n",
      "\n",
      "is_available() -> bool\n",
      "    Return a bool indicating if CUDA is currently available.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#查函数不要加括号\n",
    "help(torch.cuda.is_available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据:dataset与dataloader\n",
    "\n",
    "dataset:提供一种方式获取数据及其label\n",
    "\n",
    "dataloader：为后面的网络提供不同的数据形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义Dataset类用于读取图片数据\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,root_dir,label_dir):\n",
    "        self.root_dir = root_dir #数据集根目录\n",
    "        self.label_dir = label_dir #标签目录 ants or bees\n",
    "        self.path = os.path.join(self.root_dir,self.label_dir) #拼接路径\n",
    "        self.img_path = os.listdir(self.path) #读取路径下的所有文件名称\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_name = self.img_path[idx] #获取图片名称\n",
    "        img_path = os.path.join(self.path,img_name) #拼接图片路径\n",
    "        img = Image.open(img_path) #读取图片\n",
    "        label = self.label_dir\n",
    "        return img,label\n",
    "    def __len__(self):\n",
    "        return len(self.img_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取蚂蚁数据集\n",
    "root_dir = r'F:\\RUC\\pytorch\\数据集\\hymenoptera_data\\train'\n",
    "label_dir = 'ants'\n",
    "ants_dataset = MyDataset(root_dir,label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#打开图片\n",
    "img,label = ants_dataset.__getitem__(0)\n",
    "#或者使用:\n",
    "#img,label = ants_dataset[0]\n",
    "img.show()\n",
    "\n",
    "#查看数据集大小\n",
    "ants_dataset.__len__()\n",
    "#或者使用:\n",
    "#len(ants_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r'F:\\RUC\\pytorch\\数据集\\hymenoptera_data\\train'\n",
    "label_dir = 'bees'\n",
    "bees_dataset = MyDataset(root_dir,label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#合并数据集\n",
    "train_dataset = ants_dataset + bees_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看合并数数据集的信息\n",
    "img,label = train_dataset.__getitem__(125)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#如果是图片+标签的形式 如何读取数据\n",
    "class MyDataset2(Dataset):\n",
    "    def __init__(self,root_dir,image_dir,label_dir):\n",
    "        self.root_dir = root_dir #数据集根目录\n",
    "        self.image_dir = image_dir #图片目录\n",
    "        self.label_dir = label_dir #标签目录\n",
    "        self.image_path = os.path.join(self.root_dir,self.image_dir) #拼接路径并读取\n",
    "        self.label_path = os.path.join(self.root_dir,self.label_dir)\n",
    "        self.image_list = os.listdir(self.image_path)\n",
    "        self.label_list = os.listdir(self.label_path)\n",
    "        # 因为label 和 Image文件名相同，进行一样的排序，可以保证取出的数据和label是一一对应的\n",
    "        self.image_list.sort()\n",
    "        self.label_list.sort()\n",
    " \n",
    "    def __getitem__(self,idx):\n",
    "        #图片、标签名称/路径\n",
    "        img_name = self.image_list[idx]\n",
    "        label_name = self.label_list[idx]\n",
    "        img_item_path = os.path.join(self.root_dir, self.image_dir, img_name)\n",
    "        label_item_path = os.path.join(self.root_dir, self.label_dir, label_name)\n",
    "        #读取图片、标签\n",
    "        img = Image.open(img_item_path)\n",
    "\n",
    "        with open(label_item_path, 'r') as f:\n",
    "            label = f.readline()\n",
    "\n",
    "        # img = np.array(img)\n",
    "        #?这里为什么要转换为tensor\n",
    "        #img = self.transform(img) 暂时先不用transform\n",
    "        sample = {'img': img, 'label': label}\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r'F:\\RUC\\pytorch\\数据集\\练手数据集\\train'\n",
    "image_dir = 'ants_image'\n",
    "label_dir = 'ants_label'\n",
    "\n",
    "ants_dataset = MyDataset2(root_dir,image_dir,label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#打开图片\n",
    "ants_dataset[0]['img'].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard的使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SummaryWriter类是 PyTorch 中 torch.utils.tensorboard 模块提供的一个重要工具，主要用于将训练过程中的各种数据（如损失值、准确率、图像等）写入 TensorBoard 可以读取的日志文件，方便用户通过 TensorBoard 可视化工具直观地观察和分析模型的训练过程和性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建类\n",
    "writer = SummaryWriter('logs')\n",
    "\n",
    "for i in range(100):\n",
    "    writer.add_scalar('y = 2x',2*i,i)\n",
    "#关闭类\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 768, 3)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "#打开一张图片然后转成numpy类型\n",
    "image_path = r'F:\\RUC\\pytorch\\数据集\\练手数据集\\train\\ants_image\\0013035.jpg'\n",
    "image_PIL = Image.open(image_path)\n",
    "image_array = np.array(image_PIL)\n",
    "#查看array的通道数\n",
    "print(image_array.shape)\n",
    "\n",
    "#创建类\n",
    "writer = SummaryWriter('logs')\n",
    "#转换成numpy数组后需要修改dataformats,因为和默认的不一样\n",
    "writer.add_image('test',image_array,1,dataformats='HWC')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3608, 0.3686, 0.3686,  ..., 0.4039, 0.4000, 0.4078],\n",
       "         [0.3569, 0.3647, 0.3686,  ..., 0.4078, 0.4078, 0.4157],\n",
       "         [0.3686, 0.3608, 0.3569,  ..., 0.4039, 0.4118, 0.4157],\n",
       "         ...,\n",
       "         [0.3725, 0.3686, 0.3686,  ..., 0.8902, 0.8863, 0.8824],\n",
       "         [0.3608, 0.3608, 0.3647,  ..., 0.8941, 0.8902, 0.8902],\n",
       "         [0.3608, 0.3608, 0.3647,  ..., 0.8941, 0.8902, 0.8863]],\n",
       "\n",
       "        [[0.5686, 0.5725, 0.5725,  ..., 0.6235, 0.6196, 0.6275],\n",
       "         [0.5647, 0.5686, 0.5725,  ..., 0.6275, 0.6275, 0.6353],\n",
       "         [0.5765, 0.5647, 0.5608,  ..., 0.6314, 0.6392, 0.6431],\n",
       "         ...,\n",
       "         [0.5922, 0.5882, 0.5843,  ..., 0.9176, 0.9137, 0.9098],\n",
       "         [0.5765, 0.5765, 0.5843,  ..., 0.9137, 0.9098, 0.9098],\n",
       "         [0.5765, 0.5765, 0.5843,  ..., 0.9137, 0.9098, 0.9059]],\n",
       "\n",
       "        [[0.0039, 0.0039, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0039, 0.0039,  ..., 0.0039, 0.0000, 0.0039],\n",
       "         [0.0118, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0078],\n",
       "         ...,\n",
       "         [0.0078, 0.0039, 0.0118,  ..., 0.8902, 0.8863, 0.8824],\n",
       "         [0.0039, 0.0039, 0.0000,  ..., 0.8863, 0.8824, 0.8863],\n",
       "         [0.0039, 0.0039, 0.0000,  ..., 0.8863, 0.8863, 0.8824]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读取一个图片\n",
    "img_path = r'F:\\RUC\\pytorch\\数据集\\练手数据集\\train\\ants_image\\541630764_dbd285d63c.jpg'\n",
    "img = Image.open(img_path)\n",
    "\n",
    "#定义totensor对象 转换图片\n",
    "tensor_trans = transforms.ToTensor()\n",
    "tensor_img = tensor_trans(img)\n",
    "\n",
    "#查看tensor\n",
    "tensor_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#常见的transforms\n",
    "\n",
    "#打开一张图片\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "img = Image.open(r'F:\\RUC\\pytorch\\数据集\\练手数据集\\train\\ants_image\\2288481644_83ff7e4572.jpg')\n",
    "                 \n",
    "#compose\n",
    "#transforms.Compose将多个transforms方法组合起来使用\n",
    "#比如将图片先resize到256*256，然后随机裁剪到224*224，最后转换为tensor\n",
    "\n",
    "\n",
    "#totensor\n",
    "#将PIL Image或者 ndarray 转换为tensor，并且归一化到[0-1.0]之间\n",
    "tensor_trans = transforms.ToTensor()\n",
    "tensor_img = tensor_trans(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2784)\n",
      "tensor(-0.4431)\n"
     ]
    }
   ],
   "source": [
    "#normalize\n",
    "#将每个信道的数据标准化到设定的均值和标准差\n",
    "#标准化前\n",
    "print(tensor_img[0][0][0])\n",
    "trans_norm = transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])\n",
    "img_norm = trans_norm(tensor_img)\n",
    "#标准化后\n",
    "print(img_norm[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 500)\n",
      "(256, 256)\n"
     ]
    }
   ],
   "source": [
    "#resize\n",
    "#调整图片大小\n",
    "print(img.size)\n",
    "trans_resize = transforms.Resize((256,256))\n",
    "img_resize = trans_resize(img)\n",
    "print(img_resize.size)\n",
    "#如果要在tensorboard中显示，需要转换成tensor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomcrop\n",
    "#随机裁剪图片\n",
    "trans_random = transforms.RandomCrop(256)\n",
    "trans_compose = transforms.Compose([trans_random,tensor_trans])\n",
    "for i in range(10):\n",
    "    img_crop = trans_compose(img)\n",
    "    writer.add_image('randomcrop',img_crop,i)\n",
    "#在tensorboard中查看各步骤结果\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frog\n"
     ]
    }
   ],
   "source": [
    "#下载torchvision中的数据集且不进行transform操作\n",
    "import torchvision\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data',train=True,download=True)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data',train=False,download=True)\n",
    "\n",
    "#查看原始数据集\n",
    "img,target = train_set[0]\n",
    "img.show()\n",
    "#查看标签\n",
    "print(train_set.classes[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下载torchvision中的数据集且进行transform操作\n",
    "#用compose定义transform\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data',train=True,download=True,transform=transform)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data',train=False,download=True,transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#从torchvision中加载数据集\n",
    "from torch.utils.data import DataLoader\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data',train=False,download=True,transform=transform)\n",
    "\n",
    "test_loader = DataLoader(test_set,batch_size=64,shuffle=True,num_workers=0,drop_last=True)\n",
    "#batch_size:每次读取并合并的数据量,然后将所有数据按照该方式划分成n//4批\n",
    "\n",
    "#查看原始数据集的第一张图片及标签\n",
    "img,target = test_set[0]\n",
    "print(img.shape)\n",
    "print(target)\n",
    "\n",
    "#查看dataloader中的数据\n",
    "writer = SummaryWriter('dataloader')\n",
    "step = 0\n",
    "#epoch是指遍历整个数据集的次数\n",
    "for epoch in range(2):\n",
    "    for data in test_loader:\n",
    "        img,target = data\n",
    "        #print(img.shape)\n",
    "        #print(target)\n",
    "        writer.add_images('test_drop',img,step)\n",
    "        step += 1\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class ep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ep,self).__init__() #调用父类的构造函数\n",
    "    def forward(self,x):\n",
    "        out_put = x+1\n",
    "        return out_put\n",
    "\n",
    "model = ep()\n",
    "#输入需要是tensor类型\n",
    "input = torch.tensor(1.0)\n",
    "print(model(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([1, 1, 5, 5])\n",
      "torch.Size([1, 1, 3, 3])\n",
      "tensor([[[[ 1,  1, -1],\n",
      "          [ 0, -1, -4],\n",
      "          [-4, -3, -2]]]])\n",
      "tensor([[[[ 1, -1],\n",
      "          [-4, -2]]]])\n",
      "tensor([[[[ 3,  1,  3,  0, -6],\n",
      "          [ 5,  1,  1, -1, -6],\n",
      "          [ 5,  0, -1, -4, -4],\n",
      "          [ 5, -4, -3, -2, -2],\n",
      "          [ 3, -4, -1, -1, -2]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "input = torch.tensor([[1,2,0,3,1],[0,1,2,3,1],[1,2,1,0,0],[5,2,3,1,1],[2,1,0,1,1]])\n",
    "\n",
    "#定义卷积核\n",
    "kernel = torch.tensor([[-1,0,1],[-1,0,1],[-1,0,1]])\n",
    "\n",
    "print(input.shape)\n",
    "print(kernel.shape)\n",
    "\n",
    "#如果要进行卷进操作需要对尺寸进行变换\n",
    "#batch_size,channel,height,width\n",
    "input = torch.reshape(input,(1,1,5,5))\n",
    "kernel = torch.reshape(kernel,(1,1,3,3))\n",
    "\n",
    "print(input.shape)\n",
    "print(kernel.shape)\n",
    "\n",
    "#进行卷积操作\n",
    "#stride是步长\n",
    "output = F.conv2d(input,kernel)\n",
    "print(output)\n",
    "\n",
    "output2 = F.conv2d(input,kernel,stride=2)\n",
    "print(output2)\n",
    "\n",
    "#padding是填充\n",
    "#padding = 1,是上下左右都填充1,5*5变成7*7\n",
    "output3 = F.conv2d(input,kernel,stride=1,padding=1)\n",
    "print(output3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernel_size是卷积核的大小,不需要手动写kernel矩阵,训练过程中会对卷积核不断调优\n",
    "#out_channels是输出通道数,就是卷积核的个数\n",
    "#实际上就是使用两个卷积核进行卷积操作,再把结果合并\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "#提数据 先提成dataset再转换成dataLoader\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data2',train=False,download=True,transform=torchvision.transforms.ToTensor())\n",
    "dataloader = DataLoader(dataset,batch_size=64)\n",
    "\n",
    "#定义卷积神经网络\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        #定义卷积层\n",
    "        #为什么输入通道是3,因为图片是RGB三通道\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=6,kernel_size=3,stride=1,padding=0)\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        return x\n",
    "\n",
    "cnn = CNN()\n",
    "\n",
    "writer = SummaryWriter('cnn')\n",
    "#把数据填进网络,并在tensorboard中查看结果\n",
    "#30 = 32 - 3 + 1\n",
    "step = 0\n",
    "for data in dataloader:\n",
    "    img,target = data\n",
    "    # [64, 3, 32, 32] -> [64, 6, 30, 30]\n",
    "    output = cnn(img)\n",
    "    #要在tensorboard中查看结果需要channel不大于3\n",
    "    output = torch.reshape(output,(-1,3,30,30))\n",
    "    writer.add_images('cnn',output,step)\n",
    "    step += 1\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[2., 3.],\n",
      "          [5., 1.]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#需修改dtype=torch.float32,否则会报错\n",
    "input = torch.tensor([[1,2,0,3,1],[0,1,2,3,1],[1,2,1,0,0],[5,2,3,1,1],[2,1,0,1,1]],dtype=torch.float32)\n",
    "input = torch.reshape(input,(-1,1,5,5))\n",
    "\n",
    "#ceil_mode=True,向上取整(后面取不完的矩阵保留/不保留)\n",
    "#kenel_size=2,stride=2,就是2*2的矩阵,每次移动2个单位,不需要自己写矩阵\n",
    "\n",
    "class max_pooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(max_pooling,self).__init__()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=3,ceil_mode=True)\n",
    "    def forward(self,x):\n",
    "        x = self.max_pool(x)\n",
    "        return x\n",
    "\n",
    "model = max_pooling()\n",
    "output = model(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最大池化的作用：保留数据的特征并且减小数据量 1080p -> 720p 压缩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#直观查看maxpooling的效果\n",
    "\n",
    "#提数据 先提成dataset再转换成dataLoader\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data2',train=False,download=True,transform=torchvision.transforms.ToTensor())\n",
    "dataloader = DataLoader(dataset,batch_size=64)\n",
    "\n",
    "writer = SummaryWriter('max_pooling')\n",
    "#把数据填进网络,并在tensorboard中查看结果\n",
    "#30 = 32 - 3 + 1\n",
    "step = 0\n",
    "model = max_pooling()\n",
    "for data in dataloader:\n",
    "    img,target = data\n",
    "    # [64, 3, 32, 32] -> [64, 6, 30, 30]\n",
    "    output = model(img)\n",
    "    #要在tensorboard中查看结果需要channel不大于3\n",
    "    writer.add_images('max_pooling',output,step)\n",
    "    step += 1\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 非线性激活"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7311, 0.3775],\n",
      "        [0.2689, 0.9526]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input = torch.tensor([[1,-0.5],[-1,3]])\n",
    "\n",
    "class sigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(sigmoid,self).__init__()\n",
    "    def forward(self,x):\n",
    "        return nn.functional.sigmoid(x)\n",
    "\n",
    "model = sigmoid()\n",
    "output = model(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.CIFAR10(root='./data2',train=False,download=True,transform=torchvision.transforms.ToTensor())\n",
    "dataloader = DataLoader(dataset,batch_size=64)\n",
    "\n",
    "writer = SummaryWriter('sigmoid')\n",
    "#把数据填进网络,并在tensorboard中查看结果\n",
    "step = 0\n",
    "model = sigmoid()\n",
    "for data in dataloader:\n",
    "    img,target = data\n",
    "    writer.add_images('input',img,step)\n",
    "    output = model(img)\n",
    "    #要在tensorboard中查看结果需要channel不大于3\n",
    "    writer.add_images('output',output,step)\n",
    "    step += 1\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  线性层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3072])\n",
      "torch.Size([64, 10])\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data2',train=False,download=True,transform=torchvision.transforms.ToTensor())\n",
    "dataloader = DataLoader(dataset,batch_size=64)\n",
    "\n",
    "writer = SummaryWriter('linear')\n",
    "\n",
    "class linear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(linear,self).__init__()\n",
    "        #channel*height*width\n",
    "        self.linear = nn.Linear(3*32*32,10)\n",
    "    def forward(self,x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = linear()\n",
    "step = 0\n",
    "for data in dataloader:\n",
    "    img,target = data\n",
    "    print(img.shape)\n",
    "    img = torch.flatten(img,start_dim=1)\n",
    "    print(img.shape)\n",
    "    output = model(img)\n",
    "    print(output.shape)\n",
    "    step += 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Conv2d\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "class ep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ep,self).__init__() #调用父类的构造函数\n",
    "        self.model1 = nn.Sequential(\n",
    "            #conv中的padding通过计算得出\n",
    "            nn.Conv2d(3, 32, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            #linear的输入输出都是一维\n",
    "            nn.Linear(64*4*4, 64),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.model1(x)\n",
    "        return x\n",
    "\n",
    "model = ep()\n",
    "input = torch.ones((64,3,32,32))\n",
    "print(model(input).shape)\n",
    "\n",
    "writer = SummaryWriter('logs_seq')\n",
    "#计算图\n",
    "writer.add_graph(model,input)\n",
    "writer.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6667)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "input = torch.tensor([1,2,3],dtype=torch.float32)\n",
    "target = torch.tensor([1,2,5],dtype=torch.float32)\n",
    "\n",
    "#为什么要reshape,因为输入的数据是[3],而loss函数需要的是[1,3] 1是batch_size\n",
    "#主要关注input和target的shape\n",
    "input = torch.reshape(input,(1,1,1,3))\n",
    "target = torch.reshape(target,(1,1,1,3))\n",
    "\n",
    "loss = nn.L1Loss()\n",
    "print(loss(input,target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络类:初始化与前向传播，计算损失函数和梯度反向传播都写在外面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3211, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data2',train=False,download=True,transform=torchvision.transforms.ToTensor())\n",
    "dataloader = DataLoader(dataset,batch_size=1)\n",
    "class ep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ep,self).__init__() #调用父类的构造函数\n",
    "        self.model1 = nn.Sequential(\n",
    "            #conv中的padding通过计算得出\n",
    "            nn.Conv2d(3, 32, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            #linear的输入输出都是一维\n",
    "            nn.Linear(64*4*4, 64),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.model1(x)\n",
    "        return x\n",
    "#nn.Module与nn.Loss都要先进行初始化\n",
    "model = ep()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "for data in dataloader:\n",
    "    img,target = data\n",
    "    output = model(img)\n",
    "    #计算损失\n",
    "    loss_value = loss(output,target)\n",
    "    #反向传播写在这里\n",
    "    loss_value.backward()\n",
    "    print(loss_value)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化器\n",
    "\n",
    "torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18719.490137356333\n",
      "16121.07339965034\n",
      "15410.470019844097\n",
      "16090.60894327111\n",
      "18059.567657524676\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data2',train=False,download=True,transform=torchvision.transforms.ToTensor())\n",
    "dataloader = DataLoader(dataset,batch_size=1)\n",
    "class ep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ep,self).__init__() #调用父类的构造函数\n",
    "        self.model1 = nn.Sequential(\n",
    "            #conv中的padding通过计算得出\n",
    "            nn.Conv2d(3, 32, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            #linear的输入输出都是一维\n",
    "            nn.Linear(64*4*4, 64),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.model1(x)\n",
    "        return x\n",
    "#先进行初始化 模型/损失函数/优化器\n",
    "model = ep()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.SGD(model.parameters(),lr=0.01)\n",
    "for epoch in range(5):\n",
    "    running_loss = 0.0\n",
    "    for data in dataloader:\n",
    "        img,target = data\n",
    "        output = model(img)\n",
    "        #计算损失\n",
    "        loss_value = loss(output,target)\n",
    "        #梯度清零\n",
    "        optim.zero_grad()\n",
    "        #反向传播求梯度\n",
    "        loss_value.backward()\n",
    "        #更新参数\n",
    "        optim.step()\n",
    "        running_loss += loss_value.item()\n",
    "    print(running_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 网络模型的加载 修改 与保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch import nn\n",
    "\n",
    "#下载数据集 数据集太大了,下载不了\n",
    "#train_data = torchvision.datasets.ImageNet(root='./data',split='train',download=True,transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "#加载网络模型\n",
    "#false代表只加载了网络架构,权重是随机初始化的\n",
    "vgg16_false = torchvision.models.vgg16(pretrained=False)\n",
    "#true代表加载了网络架构和预训练权重\n",
    "vgg16_true = torchvision.models.vgg16(pretrained=True)\n",
    "\n",
    "#根据ImageNet数据集是将结果分为1000类,所以输出层是1000\n",
    "#我们的数据集是10类,所以需要修改输出层\n",
    "\n",
    "#如何在现有网络结构上增加层\n",
    "vgg16_true.classifier.add_module('add_linear',torch.nn.Linear(1000,10))\n",
    "print(vgg16_true)\n",
    "\n",
    "#如何修改网络结构 先查看网络结构再修改\n",
    "print(vgg16_false)\n",
    "vgg16_false.classifier[6] = nn.Linear(4096,10)\n",
    "\n",
    "#模型保存\n",
    "#不仅保存了网络结构,还保存了网络参数 \n",
    "torch.save(vgg16_false,'vgg16_method1.pth')\n",
    "#模型读取 在读取的时候如果是自定义的网络类,需要先定义网络类,然后再读取\n",
    "model = torch.load('vgg16_method1.pth')\n",
    "\n",
    "#只保存网络参数(推荐)\n",
    "torch.save(vgg16_false.state_dict(),'vgg16_method2.pth')\n",
    "#模型读取 先加载网络结构,再加载网络参数\n",
    "vgg16 = torchvision.models.vgg16(pretrained=False)\n",
    "vgg16.load_state_dict(torch.load('vgg16_method2.pth'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完整的模型训练套路"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if __name__ == '__main__'的作用：这一块下的代码在导入py文件作为模块时不会执行，因此需要测试的代码可以写在这下面，保证既能测试又不会干扰到模块导入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "-------第1轮训练-------\n",
      "训练次数:100,loss:2.295605421066284\n",
      "整体测试集上的loss:358.8218688964844\n",
      "整体测试集上的准确率:0.1194\n",
      "第1轮训练结束,模型已保存\n",
      "-------第2轮训练-------\n",
      "训练次数:200,loss:2.2575814723968506\n",
      "训练次数:300,loss:2.2438008785247803\n",
      "整体测试集上的loss:349.9715576171875\n",
      "整体测试集上的准确率:0.1497\n",
      "第2轮训练结束,模型已保存\n",
      "-------第3轮训练-------\n",
      "训练次数:400,loss:2.165344476699829\n",
      "整体测试集上的loss:359.5679016113281\n",
      "整体测试集上的准确率:0.1724\n",
      "第3轮训练结束,模型已保存\n",
      "-------第4轮训练-------\n",
      "训练次数:500,loss:2.081733465194702\n",
      "训练次数:600,loss:1.9648451805114746\n",
      "整体测试集上的loss:350.31103515625\n",
      "整体测试集上的准确率:0.2052\n",
      "第4轮训练结束,模型已保存\n",
      "-------第5轮训练-------\n",
      "训练次数:700,loss:2.0468826293945312\n",
      "整体测试集上的loss:339.18426513671875\n",
      "整体测试集上的准确率:0.2285\n",
      "第5轮训练结束,模型已保存\n",
      "-------第6轮训练-------\n",
      "训练次数:800,loss:2.0016677379608154\n",
      "训练次数:900,loss:1.908528447151184\n",
      "整体测试集上的loss:328.724609375\n",
      "整体测试集上的准确率:0.2575\n",
      "第6轮训练结束,模型已保存\n",
      "-------第7轮训练-------\n",
      "训练次数:1000,loss:1.840943455696106\n",
      "整体测试集上的loss:315.4854431152344\n",
      "整体测试集上的准确率:0.2987\n",
      "第7轮训练结束,模型已保存\n",
      "-------第8轮训练-------\n",
      "训练次数:1100,loss:1.9281686544418335\n",
      "训练次数:1200,loss:1.9925345182418823\n",
      "整体测试集上的loss:299.8179016113281\n",
      "整体测试集上的准确率:0.3349\n",
      "第8轮训练结束,模型已保存\n",
      "-------第9轮训练-------\n",
      "训练次数:1300,loss:1.799347162246704\n",
      "训练次数:1400,loss:1.6056288480758667\n",
      "整体测试集上的loss:289.4259033203125\n",
      "整体测试集上的准确率:0.3515\n",
      "第9轮训练结束,模型已保存\n",
      "-------第10轮训练-------\n",
      "训练次数:1500,loss:1.7473547458648682\n",
      "整体测试集上的loss:281.6627502441406\n",
      "整体测试集上的准确率:0.3671\n",
      "第10轮训练结束,模型已保存\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from model import *\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "#提取数据\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data2',train=False,download=True,transform=torchvision.transforms.ToTensor())\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data2',train=False,download=True,transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "\n",
    "#加载数据集\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=64)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=64)\n",
    "\n",
    "#定义网络 从写好的模块中import\n",
    "model1 = example_model()\n",
    "\n",
    "#定义损失函数\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "#定义优化器\n",
    "optim = torch.optim.SGD(model1.parameters(),lr=0.01)\n",
    "\n",
    "#记录训练次数\n",
    "total_train_step = 0\n",
    "#记录测试次数\n",
    "total_test_step = 0\n",
    "#训练轮数\n",
    "epoch = 10\n",
    "\n",
    "#添加tensorboard\n",
    "writer = SummaryWriter('logs_train')\n",
    "\n",
    "#训练\n",
    "for i in range(epoch):\n",
    "    print('-------第{}轮训练-------'.format(i+1))\n",
    "    #设置为训练模式 有些层在训练和测试的时候是不一样的比如dropout batchnorm,如果没有这些层可以不写\n",
    "    #model1.train()\n",
    "    for data in train_dataloader:\n",
    "        img,target = data\n",
    "        output = model1(img)\n",
    "        loss_value = loss(output,target)\n",
    "        optim.zero_grad()\n",
    "        loss_value.backward()\n",
    "        optim.step()\n",
    "        total_train_step += 1\n",
    "        if total_train_step % 100 == 0:\n",
    "            print('训练次数:{},loss:{}'.format(total_train_step,loss_value.item()))\n",
    "            writer.add_scalar('train_loss',loss_value.item(),total_train_step)\n",
    "    #每轮结束后测试\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    #model1.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            img,target = data\n",
    "            output = model1(img)\n",
    "            loss_value = loss(output,target)\n",
    "            total_test_loss += loss_value\n",
    "            accuracy = (output.argmax(1) == target).sum().item()\n",
    "            total_accuracy += accuracy\n",
    "        print('整体测试集上的loss:{}'.format(total_test_loss))\n",
    "        print('整体测试集上的准确率:{}'.format(total_accuracy/len(test_dataset)))\n",
    "        writer.add_scalar('test_loss',total_test_loss,total_test_step)\n",
    "        total_test_step += 1\n",
    "    \n",
    "    #每一轮训练后保存模型\n",
    "    torch.save(model1.state_dict(),f'model_result/model_epoch_{i+1}.pth')\n",
    "    print('第{}轮训练结束,模型已保存'.format(i+1))\n",
    "\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 利用GPU训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000\n",
      "10000\n",
      "-------第1轮训练-------\n",
      "训练次数:100,loss:2.279947519302368\n",
      "整体测试集上的loss:358.63446044921875\n",
      "整体测试集上的准确率:0.1022\n",
      "第1轮训练结束,模型已保存\n",
      "-------第2轮训练-------\n",
      "训练次数:200,loss:2.2543952465057373\n",
      "训练次数:300,loss:2.2643587589263916\n",
      "整体测试集上的loss:351.9914855957031\n",
      "整体测试集上的准确率:0.1363\n",
      "第2轮训练结束,模型已保存\n",
      "-------第3轮训练-------\n",
      "训练次数:400,loss:2.1930794715881348\n",
      "整体测试集上的loss:340.8009948730469\n",
      "整体测试集上的准确率:0.1741\n",
      "第3轮训练结束,模型已保存\n",
      "-------第4轮训练-------\n",
      "训练次数:500,loss:2.057234287261963\n",
      "训练次数:600,loss:1.9654277563095093\n",
      "整体测试集上的loss:349.7891845703125\n",
      "整体测试集上的准确率:0.2087\n",
      "第4轮训练结束,模型已保存\n",
      "-------第5轮训练-------\n",
      "训练次数:700,loss:2.0554873943328857\n",
      "整体测试集上的loss:340.4717712402344\n",
      "整体测试集上的准确率:0.2328\n",
      "第5轮训练结束,模型已保存\n",
      "-------第6轮训练-------\n",
      "训练次数:800,loss:1.9749749898910522\n",
      "训练次数:900,loss:1.8851568698883057\n",
      "整体测试集上的loss:328.9405517578125\n",
      "整体测试集上的准确率:0.2624\n",
      "第6轮训练结束,模型已保存\n",
      "-------第7轮训练-------\n",
      "训练次数:1000,loss:1.8195239305496216\n",
      "整体测试集上的loss:314.12530517578125\n",
      "整体测试集上的准确率:0.3036\n",
      "第7轮训练结束,模型已保存\n",
      "-------第8轮训练-------\n",
      "训练次数:1100,loss:1.9189614057540894\n",
      "训练次数:1200,loss:1.9924283027648926\n",
      "整体测试集上的loss:300.37908935546875\n",
      "整体测试集上的准确率:0.3318\n",
      "第8轮训练结束,模型已保存\n",
      "-------第9轮训练-------\n",
      "训练次数:1300,loss:1.7667597532272339\n",
      "训练次数:1400,loss:1.6007989645004272\n",
      "整体测试集上的loss:290.18878173828125\n",
      "整体测试集上的准确率:0.3492\n",
      "第9轮训练结束,模型已保存\n",
      "-------第10轮训练-------\n",
      "训练次数:1500,loss:1.7227214574813843\n",
      "整体测试集上的loss:282.1357727050781\n",
      "整体测试集上的准确率:0.364\n",
      "第10轮训练结束,模型已保存\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter\n",
    "#from model import *\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "import torch\n",
    "#提取数据\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data2',train=False,download=True,transform=torchvision.transforms.ToTensor())\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data2',train=False,download=True,transform=torchvision.transforms.ToTensor())\n",
    "\n",
    "print(len(train_dataset))\n",
    "print(len(test_dataset))\n",
    "\n",
    "#加载数据集\n",
    "train_dataloader = DataLoader(train_dataset,batch_size=64)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=64)\n",
    "\n",
    "class example_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(example_model,self).__init__() #调用父类的构造函数\n",
    "        self.model1 = nn.Sequential(\n",
    "            #conv中的padding通过计算得出\n",
    "            nn.Conv2d(3, 32, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            #linear的输入输出都是一维\n",
    "            nn.Linear(64*4*4, 64),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.model1(x)\n",
    "        return x\n",
    "\n",
    "#定义网络 从写好的模块中import\n",
    "model1 = example_model()\n",
    "#将网络模型放到GPU上\n",
    "model1 = model1.cuda()\n",
    "\n",
    "#定义损失函数\n",
    "loss = nn.CrossEntropyLoss()\n",
    "#将损失函数放到GPU上\n",
    "loss = loss.cuda()\n",
    "\n",
    "#定义优化器\n",
    "optim = torch.optim.SGD(model1.parameters(),lr=0.01)\n",
    "\n",
    "\n",
    "#记录训练次数\n",
    "total_train_step = 0\n",
    "#记录测试次数\n",
    "total_test_step = 0\n",
    "#训练轮数\n",
    "epoch = 10\n",
    "\n",
    "#添加tensorboard\n",
    "writer = SummaryWriter('logs_train')\n",
    "\n",
    "#训练\n",
    "for i in range(epoch):\n",
    "    print('-------第{}轮训练-------'.format(i+1))\n",
    "    #设置为训练模式 有些层在训练和测试的时候是不一样的比如dropout batchnorm,如果没有这些层可以不写\n",
    "    #model1.train()\n",
    "    for data in train_dataloader:\n",
    "        img,target = data\n",
    "        #将数据放到GPU上\n",
    "        img = img.cuda()\n",
    "        target = target.cuda()\n",
    "        output = model1(img)\n",
    "        loss_value = loss(output,target)\n",
    "        optim.zero_grad()\n",
    "        loss_value.backward()\n",
    "        optim.step()\n",
    "        total_train_step += 1\n",
    "        if total_train_step % 100 == 0:\n",
    "            print('训练次数:{},loss:{}'.format(total_train_step,loss_value.item()))\n",
    "            writer.add_scalar('train_loss',loss_value.item(),total_train_step)\n",
    "    #每轮结束后测试\n",
    "    total_test_loss = 0\n",
    "    total_accuracy = 0\n",
    "    #model1.eval()\n",
    "    with torch.no_grad():\n",
    "        for data in test_dataloader:\n",
    "            img,target = data\n",
    "            img = img.cuda()\n",
    "            target = target.cuda()\n",
    "            output = model1(img)\n",
    "            loss_value = loss(output,target)\n",
    "            total_test_loss += loss_value\n",
    "            accuracy = (output.argmax(1) == target).sum().item()\n",
    "            total_accuracy += accuracy\n",
    "        print('整体测试集上的loss:{}'.format(total_test_loss))\n",
    "        print('整体测试集上的准确率:{}'.format(total_accuracy/len(test_dataset)))\n",
    "        writer.add_scalar('test_loss',total_test_loss,total_test_step)\n",
    "        total_test_step += 1\n",
    "    \n",
    "    #每一轮训练后保存模型\n",
    "    torch.save(model1.state_dict(),f'./model_result/model_epoch_{i+1}.pth')\n",
    "    print('第{}轮训练结束,模型已保存'.format(i+1))\n",
    "\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#或者还可以定义device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "#将模型和数据放到device上即可\n",
    "model1 = model1.to(device)\n",
    "loss = loss.to(device)\n",
    "img = img.to(device)\n",
    "target = target.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 完整的模型验证套路\n",
    "利用训练好的模型，给它提供输入"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图像模式: RGBA\n",
      "图像模式: RGB\n",
      "tensor([[ 0.6116, -0.9340,  0.6041,  0.3099,  0.5167,  1.2334, -1.1872,  0.6139,\n",
      "         -0.9747, -1.7588]])\n"
     ]
    }
   ],
   "source": [
    "#提供一个外源图片输入 然后输出预测结果\n",
    "\n",
    "from PIL import Image\n",
    "from model import *\n",
    "\n",
    "image_path = './数据集/dog_test.png'\n",
    "image = Image.open(image_path)\n",
    "# 查看图像模式\n",
    "print(\"图像模式:\", image.mode)\n",
    "\n",
    "# 转换图像模式\n",
    "image = image.convert('RGB')\n",
    "print(\"图像模式:\", image.mode)\n",
    "\n",
    "# 转换图像大小 batch\n",
    "transform = torchvision.transforms.Compose([torchvision.transforms.Resize((32, 32)), torchvision.transforms.ToTensor()])\n",
    "image = transform(image)\n",
    "image = torch.reshape(image, (1, 3, 32, 32))\n",
    "\n",
    "# 加载模型\n",
    "model = example_model()\n",
    "# 加载模型参数\n",
    "model.load_state_dict(torch.load('./model_result/model_epoch_10.pth'))\n",
    "\n",
    "# 预测 不要忘记将模型设置为eval模式\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(image)\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
