{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查询package里的函数以及函数如何使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Any',\n",
       " 'BFloat16Storage',\n",
       " 'BFloat16Tensor',\n",
       " 'BoolStorage',\n",
       " 'BoolTensor',\n",
       " 'ByteStorage',\n",
       " 'ByteTensor',\n",
       " 'CUDAGraph',\n",
       " 'CUDAPluggableAllocator',\n",
       " 'Callable',\n",
       " 'CharStorage',\n",
       " 'CharTensor',\n",
       " 'ComplexDoubleStorage',\n",
       " 'ComplexFloatStorage',\n",
       " 'CudaError',\n",
       " 'DeferredCudaCallError',\n",
       " 'Device',\n",
       " 'DoubleStorage',\n",
       " 'DoubleTensor',\n",
       " 'Event',\n",
       " 'ExternalStream',\n",
       " 'FloatStorage',\n",
       " 'FloatTensor',\n",
       " 'HalfStorage',\n",
       " 'HalfTensor',\n",
       " 'IntStorage',\n",
       " 'IntTensor',\n",
       " 'List',\n",
       " 'LongStorage',\n",
       " 'LongTensor',\n",
       " 'MemPool',\n",
       " 'MemPoolContext',\n",
       " 'Optional',\n",
       " 'OutOfMemoryError',\n",
       " 'ShortStorage',\n",
       " 'ShortTensor',\n",
       " 'Stream',\n",
       " 'StreamContext',\n",
       " 'Tuple',\n",
       " 'Union',\n",
       " '_CudaBase',\n",
       " '_CudaDeviceProperties',\n",
       " '_DeviceGuard',\n",
       " '_HAS_PYNVML',\n",
       " '_LazySeedTracker',\n",
       " '_PYNVML_ERR',\n",
       " '_WrappedTritonKernel',\n",
       " '__all__',\n",
       " '__annotations__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_cached_device_count',\n",
       " '_check_bf16_tensor_supported',\n",
       " '_check_capability',\n",
       " '_check_cubins',\n",
       " '_cudart',\n",
       " '_device',\n",
       " '_device_count_amdsmi',\n",
       " '_device_count_nvml',\n",
       " '_device_t',\n",
       " '_dummy_type',\n",
       " '_exchange_device',\n",
       " '_extract_arch_version',\n",
       " '_get_amdsmi_clock_rate',\n",
       " '_get_amdsmi_device_index',\n",
       " '_get_amdsmi_device_memory_used',\n",
       " '_get_amdsmi_handler',\n",
       " '_get_amdsmi_memory_usage',\n",
       " '_get_amdsmi_power_draw',\n",
       " '_get_amdsmi_temperature',\n",
       " '_get_amdsmi_utilization',\n",
       " '_get_device',\n",
       " '_get_device_index',\n",
       " '_get_generator',\n",
       " '_get_nvml_device_index',\n",
       " '_get_pynvml_handler',\n",
       " '_get_rng_state_offset',\n",
       " '_initialization_lock',\n",
       " '_initialized',\n",
       " '_is_compiled',\n",
       " '_is_in_bad_fork',\n",
       " '_lazy_call',\n",
       " '_lazy_init',\n",
       " '_lazy_new',\n",
       " '_lazy_seed_tracker',\n",
       " '_maybe_exchange_device',\n",
       " '_memory_viz',\n",
       " '_nvml_based_avail',\n",
       " '_parse_visible_devices',\n",
       " '_queued_calls',\n",
       " '_raw_device_count_amdsmi',\n",
       " '_raw_device_count_nvml',\n",
       " '_raw_device_uuid_amdsmi',\n",
       " '_raw_device_uuid_nvml',\n",
       " '_register_triton_kernels',\n",
       " '_set_rng_state_offset',\n",
       " '_set_stream_by_id',\n",
       " '_sleep',\n",
       " '_tls',\n",
       " '_transform_uuid_to_ordinals',\n",
       " '_utils',\n",
       " '_warn_typed_storage_removal',\n",
       " 'amp',\n",
       " 'caching_allocator_alloc',\n",
       " 'caching_allocator_delete',\n",
       " 'caching_allocator_enable',\n",
       " 'can_device_access_peer',\n",
       " 'cast',\n",
       " 'change_current_allocator',\n",
       " 'check_error',\n",
       " 'classproperty',\n",
       " 'clock_rate',\n",
       " 'cudaStatus',\n",
       " 'cudart',\n",
       " 'current_blas_handle',\n",
       " 'current_device',\n",
       " 'current_stream',\n",
       " 'default_generators',\n",
       " 'default_stream',\n",
       " 'device',\n",
       " 'device_count',\n",
       " 'device_memory_used',\n",
       " 'device_of',\n",
       " 'empty_cache',\n",
       " 'gds',\n",
       " 'get_allocator_backend',\n",
       " 'get_arch_list',\n",
       " 'get_device_capability',\n",
       " 'get_device_name',\n",
       " 'get_device_properties',\n",
       " 'get_gencode_flags',\n",
       " 'get_per_process_memory_fraction',\n",
       " 'get_rng_state',\n",
       " 'get_rng_state_all',\n",
       " 'get_sync_debug_mode',\n",
       " 'graph',\n",
       " 'graph_pool_handle',\n",
       " 'graphs',\n",
       " 'has_half',\n",
       " 'has_magma',\n",
       " 'importlib',\n",
       " 'init',\n",
       " 'initial_seed',\n",
       " 'ipc_collect',\n",
       " 'is_available',\n",
       " 'is_bf16_supported',\n",
       " 'is_current_stream_capturing',\n",
       " 'is_initialized',\n",
       " 'jiterator',\n",
       " 'list_gpu_processes',\n",
       " 'lru_cache',\n",
       " 'make_graphed_callables',\n",
       " 'manual_seed',\n",
       " 'manual_seed_all',\n",
       " 'max_memory_allocated',\n",
       " 'max_memory_cached',\n",
       " 'max_memory_reserved',\n",
       " 'mem_get_info',\n",
       " 'memory',\n",
       " 'memory_allocated',\n",
       " 'memory_cached',\n",
       " 'memory_reserved',\n",
       " 'memory_snapshot',\n",
       " 'memory_stats',\n",
       " 'memory_stats_as_nested_dict',\n",
       " 'memory_summary',\n",
       " 'memory_usage',\n",
       " 'nccl',\n",
       " 'nvtx',\n",
       " 'os',\n",
       " 'power_draw',\n",
       " 'profiler',\n",
       " 'random',\n",
       " 'reset_accumulated_memory_stats',\n",
       " 'reset_max_memory_allocated',\n",
       " 'reset_max_memory_cached',\n",
       " 'reset_peak_memory_stats',\n",
       " 'seed',\n",
       " 'seed_all',\n",
       " 'set_device',\n",
       " 'set_per_process_memory_fraction',\n",
       " 'set_rng_state',\n",
       " 'set_rng_state_all',\n",
       " 'set_stream',\n",
       " 'set_sync_debug_mode',\n",
       " 'sparse',\n",
       " 'stream',\n",
       " 'streams',\n",
       " 'synchronize',\n",
       " 'temperature',\n",
       " 'threading',\n",
       " 'torch',\n",
       " 'traceback',\n",
       " 'tunable',\n",
       " 'use_mem_pool',\n",
       " 'utilization',\n",
       " 'warnings']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(torch.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function is_available in module torch.cuda:\n",
      "\n",
      "is_available() -> bool\n",
      "    Return a bool indicating if CUDA is currently available.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#查函数不要加括号\n",
    "help(torch.cuda.is_available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据:dataset与dataloader\n",
    "\n",
    "dataset:提供一种方式获取数据及其label\n",
    "\n",
    "dataloader：为后面的网络提供不同的数据形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义Dataset类用于读取图片数据\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,root_dir,label_dir):\n",
    "        self.root_dir = root_dir #数据集根目录\n",
    "        self.label_dir = label_dir #标签目录 ants or bees\n",
    "        self.path = os.path.join(self.root_dir,self.label_dir) #拼接路径\n",
    "        self.img_path = os.listdir(self.path) #读取路径下的所有文件名称\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_name = self.img_path[idx] #获取图片名称\n",
    "        img_path = os.path.join(self.path,img_name) #拼接图片路径\n",
    "        img = Image.open(img_path) #读取图片\n",
    "        label = self.label_dir\n",
    "        return img,label\n",
    "    def __len__(self):\n",
    "        return len(self.img_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取蚂蚁数据集\n",
    "root_dir = r'F:\\RUC\\pytorch\\数据集\\hymenoptera_data\\train'\n",
    "label_dir = 'ants'\n",
    "ants_dataset = MyDataset(root_dir,label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#打开图片\n",
    "img,label = ants_dataset.__getitem__(0)\n",
    "#或者使用:\n",
    "#img,label = ants_dataset[0]\n",
    "img.show()\n",
    "\n",
    "#查看数据集大小\n",
    "ants_dataset.__len__()\n",
    "#或者使用:\n",
    "#len(ants_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r'F:\\RUC\\pytorch\\数据集\\hymenoptera_data\\train'\n",
    "label_dir = 'bees'\n",
    "bees_dataset = MyDataset(root_dir,label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#合并数据集\n",
    "train_dataset = ants_dataset + bees_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看合并数数据集的信息\n",
    "img,label = train_dataset.__getitem__(125)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#如果是图片+标签的形式 如何读取数据\n",
    "class MyDataset2(Dataset):\n",
    "    def __init__(self,root_dir,image_dir,label_dir):\n",
    "        self.root_dir = root_dir #数据集根目录\n",
    "        self.image_dir = image_dir #图片目录\n",
    "        self.label_dir = label_dir #标签目录\n",
    "        self.image_path = os.path.join(self.root_dir,self.image_dir) #拼接路径并读取\n",
    "        self.label_path = os.path.join(self.root_dir,self.label_dir)\n",
    "        self.image_list = os.listdir(self.image_path)\n",
    "        self.label_list = os.listdir(self.label_path)\n",
    "        # 因为label 和 Image文件名相同，进行一样的排序，可以保证取出的数据和label是一一对应的\n",
    "        self.image_list.sort()\n",
    "        self.label_list.sort()\n",
    " \n",
    "    def __getitem__(self,idx):\n",
    "        #图片、标签名称/路径\n",
    "        img_name = self.image_list[idx]\n",
    "        label_name = self.label_list[idx]\n",
    "        img_item_path = os.path.join(self.root_dir, self.image_dir, img_name)\n",
    "        label_item_path = os.path.join(self.root_dir, self.label_dir, label_name)\n",
    "        #读取图片、标签\n",
    "        img = Image.open(img_item_path)\n",
    "\n",
    "        with open(label_item_path, 'r') as f:\n",
    "            label = f.readline()\n",
    "\n",
    "        # img = np.array(img)\n",
    "        #?这里为什么要转换为tensor\n",
    "        #img = self.transform(img) 暂时先不用transform\n",
    "        sample = {'img': img, 'label': label}\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r'F:\\RUC\\pytorch\\数据集\\练手数据集\\train'\n",
    "image_dir = 'ants_image'\n",
    "label_dir = 'ants_label'\n",
    "\n",
    "ants_dataset = MyDataset2(root_dir,image_dir,label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#打开图片\n",
    "ants_dataset[0]['img'].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard的使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SummaryWriter类是 PyTorch 中 torch.utils.tensorboard 模块提供的一个重要工具，主要用于将训练过程中的各种数据（如损失值、准确率、图像等）写入 TensorBoard 可以读取的日志文件，方便用户通过 TensorBoard 可视化工具直观地观察和分析模型的训练过程和性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建类\n",
    "writer = SummaryWriter('logs')\n",
    "\n",
    "for i in range(100):\n",
    "    writer.add_scalar('y = 2x',2*i,i)\n",
    "#关闭类\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 768, 3)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "#打开一张图片然后转成numpy类型\n",
    "image_path = r'F:\\RUC\\pytorch\\数据集\\练手数据集\\train\\ants_image\\0013035.jpg'\n",
    "image_PIL = Image.open(image_path)\n",
    "image_array = np.array(image_PIL)\n",
    "#查看array的通道数\n",
    "print(image_array.shape)\n",
    "\n",
    "#创建类\n",
    "writer = SummaryWriter('logs')\n",
    "#转换成numpy数组后需要修改dataformats,因为和默认的不一样\n",
    "writer.add_image('test',image_array,1,dataformats='HWC')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3608, 0.3686, 0.3686,  ..., 0.4039, 0.4000, 0.4078],\n",
       "         [0.3569, 0.3647, 0.3686,  ..., 0.4078, 0.4078, 0.4157],\n",
       "         [0.3686, 0.3608, 0.3569,  ..., 0.4039, 0.4118, 0.4157],\n",
       "         ...,\n",
       "         [0.3725, 0.3686, 0.3686,  ..., 0.8902, 0.8863, 0.8824],\n",
       "         [0.3608, 0.3608, 0.3647,  ..., 0.8941, 0.8902, 0.8902],\n",
       "         [0.3608, 0.3608, 0.3647,  ..., 0.8941, 0.8902, 0.8863]],\n",
       "\n",
       "        [[0.5686, 0.5725, 0.5725,  ..., 0.6235, 0.6196, 0.6275],\n",
       "         [0.5647, 0.5686, 0.5725,  ..., 0.6275, 0.6275, 0.6353],\n",
       "         [0.5765, 0.5647, 0.5608,  ..., 0.6314, 0.6392, 0.6431],\n",
       "         ...,\n",
       "         [0.5922, 0.5882, 0.5843,  ..., 0.9176, 0.9137, 0.9098],\n",
       "         [0.5765, 0.5765, 0.5843,  ..., 0.9137, 0.9098, 0.9098],\n",
       "         [0.5765, 0.5765, 0.5843,  ..., 0.9137, 0.9098, 0.9059]],\n",
       "\n",
       "        [[0.0039, 0.0039, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0039, 0.0039,  ..., 0.0039, 0.0000, 0.0039],\n",
       "         [0.0118, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0078],\n",
       "         ...,\n",
       "         [0.0078, 0.0039, 0.0118,  ..., 0.8902, 0.8863, 0.8824],\n",
       "         [0.0039, 0.0039, 0.0000,  ..., 0.8863, 0.8824, 0.8863],\n",
       "         [0.0039, 0.0039, 0.0000,  ..., 0.8863, 0.8863, 0.8824]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读取一个图片\n",
    "img_path = r'F:\\RUC\\pytorch\\数据集\\练手数据集\\train\\ants_image\\541630764_dbd285d63c.jpg'\n",
    "img = Image.open(img_path)\n",
    "\n",
    "#定义totensor对象 转换图片\n",
    "tensor_trans = transforms.ToTensor()\n",
    "tensor_img = tensor_trans(img)\n",
    "\n",
    "#查看tensor\n",
    "tensor_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#常见的transforms\n",
    "\n",
    "#打开一张图片\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "img = Image.open(r'F:\\RUC\\pytorch\\数据集\\练手数据集\\train\\ants_image\\2288481644_83ff7e4572.jpg')\n",
    "                 \n",
    "#compose\n",
    "#transforms.Compose将多个transforms方法组合起来使用\n",
    "#比如将图片先resize到256*256，然后随机裁剪到224*224，最后转换为tensor\n",
    "\n",
    "\n",
    "#totensor\n",
    "#将PIL Image或者 ndarray 转换为tensor，并且归一化到[0-1.0]之间\n",
    "tensor_trans = transforms.ToTensor()\n",
    "tensor_img = tensor_trans(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2784)\n",
      "tensor(-0.4431)\n"
     ]
    }
   ],
   "source": [
    "#normalize\n",
    "#将每个信道的数据标准化到设定的均值和标准差\n",
    "#标准化前\n",
    "print(tensor_img[0][0][0])\n",
    "trans_norm = transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])\n",
    "img_norm = trans_norm(tensor_img)\n",
    "#标准化后\n",
    "print(img_norm[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 500)\n",
      "(256, 256)\n"
     ]
    }
   ],
   "source": [
    "#resize\n",
    "#调整图片大小\n",
    "print(img.size)\n",
    "trans_resize = transforms.Resize((256,256))\n",
    "img_resize = trans_resize(img)\n",
    "print(img_resize.size)\n",
    "#如果要在tensorboard中显示，需要转换成tensor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomcrop\n",
    "#随机裁剪图片\n",
    "trans_random = transforms.RandomCrop(256)\n",
    "trans_compose = transforms.Compose([trans_random,tensor_trans])\n",
    "for i in range(10):\n",
    "    img_crop = trans_compose(img)\n",
    "    writer.add_image('randomcrop',img_crop,i)\n",
    "#在tensorboard中查看各步骤结果\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frog\n"
     ]
    }
   ],
   "source": [
    "#下载torchvision中的数据集且不进行transform操作\n",
    "import torchvision\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data',train=True,download=True)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data',train=False,download=True)\n",
    "\n",
    "#查看原始数据集\n",
    "img,target = train_set[0]\n",
    "img.show()\n",
    "#查看标签\n",
    "print(train_set.classes[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下载torchvision中的数据集且进行transform操作\n",
    "#用compose定义transform\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data',train=True,download=True,transform=transform)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data',train=False,download=True,transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#从torchvision中加载数据集\n",
    "from torch.utils.data import DataLoader\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data',train=False,download=True,transform=transform)\n",
    "\n",
    "test_loader = DataLoader(test_set,batch_size=64,shuffle=True,num_workers=0,drop_last=True)\n",
    "#batch_size:每次读取并合并的数据量,然后将所有数据按照该方式划分成n//4批\n",
    "\n",
    "#查看原始数据集的第一张图片及标签\n",
    "img,target = test_set[0]\n",
    "print(img.shape)\n",
    "print(target)\n",
    "\n",
    "#查看dataloader中的数据\n",
    "writer = SummaryWriter('dataloader')\n",
    "step = 0\n",
    "#epoch是指遍历整个数据集的次数\n",
    "for epoch in range(2):\n",
    "    for data in test_loader:\n",
    "        img,target = data\n",
    "        #print(img.shape)\n",
    "        #print(target)\n",
    "        writer.add_images('test_drop',img,step)\n",
    "        step += 1\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### nn.Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.)\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "\n",
    "class ep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ep,self).__init__() #调用父类的构造函数\n",
    "    def forward(self,x):\n",
    "        out_put = x+1\n",
    "        return out_put\n",
    "\n",
    "model = ep()\n",
    "#输入需要是tensor类型\n",
    "input = torch.tensor(1.0)\n",
    "print(model(input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 5])\n",
      "torch.Size([3, 3])\n",
      "torch.Size([1, 1, 5, 5])\n",
      "torch.Size([1, 1, 3, 3])\n",
      "tensor([[[[ 1,  1, -1],\n",
      "          [ 0, -1, -4],\n",
      "          [-4, -3, -2]]]])\n",
      "tensor([[[[ 1, -1],\n",
      "          [-4, -2]]]])\n",
      "tensor([[[[ 3,  1,  3,  0, -6],\n",
      "          [ 5,  1,  1, -1, -6],\n",
      "          [ 5,  0, -1, -4, -4],\n",
      "          [ 5, -4, -3, -2, -2],\n",
      "          [ 3, -4, -1, -1, -2]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "input = torch.tensor([[1,2,0,3,1],[0,1,2,3,1],[1,2,1,0,0],[5,2,3,1,1],[2,1,0,1,1]])\n",
    "\n",
    "#定义卷积核\n",
    "kernel = torch.tensor([[-1,0,1],[-1,0,1],[-1,0,1]])\n",
    "\n",
    "print(input.shape)\n",
    "print(kernel.shape)\n",
    "\n",
    "#如果要进行卷进操作需要对尺寸进行变换\n",
    "#batch_size,channel,height,width\n",
    "input = torch.reshape(input,(1,1,5,5))\n",
    "kernel = torch.reshape(kernel,(1,1,3,3))\n",
    "\n",
    "print(input.shape)\n",
    "print(kernel.shape)\n",
    "\n",
    "#进行卷积操作\n",
    "#stride是步长\n",
    "output = F.conv2d(input,kernel)\n",
    "print(output)\n",
    "\n",
    "output2 = F.conv2d(input,kernel,stride=2)\n",
    "print(output2)\n",
    "\n",
    "#padding是填充\n",
    "#padding = 1,是上下左右都填充1,5*5变成7*7\n",
    "output3 = F.conv2d(input,kernel,stride=1,padding=1)\n",
    "print(output3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#kernel_size是卷积核的大小,不需要手动写kernel矩阵,训练过程中会对卷积核不断调优\n",
    "#out_channels是输出通道数,就是卷积核的个数\n",
    "#实际上就是使用两个卷积核进行卷积操作,再把结果合并\n",
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "\n",
    "#提数据 先提成dataset再转换成dataLoader\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data2',train=False,download=True,transform=torchvision.transforms.ToTensor())\n",
    "dataloader = DataLoader(dataset,batch_size=64)\n",
    "\n",
    "#定义卷积神经网络\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        #定义卷积层\n",
    "        #为什么输入通道是3,因为图片是RGB三通道\n",
    "        self.conv1 = nn.Conv2d(in_channels=3,out_channels=6,kernel_size=3,stride=1,padding=0)\n",
    "    def forward(self,x):\n",
    "        x = self.conv1(x)\n",
    "        return x\n",
    "\n",
    "cnn = CNN()\n",
    "\n",
    "writer = SummaryWriter('cnn')\n",
    "#把数据填进网络,并在tensorboard中查看结果\n",
    "#30 = 32 - 3 + 1\n",
    "step = 0\n",
    "for data in dataloader:\n",
    "    img,target = data\n",
    "    # [64, 3, 32, 32] -> [64, 6, 30, 30]\n",
    "    output = cnn(img)\n",
    "    #要在tensorboard中查看结果需要channel不大于3\n",
    "    output = torch.reshape(output,(-1,3,30,30))\n",
    "    writer.add_images('cnn',output,step)\n",
    "    step += 1\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pooling layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[[2., 3.],\n",
      "          [5., 1.]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "#需修改dtype=torch.float32,否则会报错\n",
    "input = torch.tensor([[1,2,0,3,1],[0,1,2,3,1],[1,2,1,0,0],[5,2,3,1,1],[2,1,0,1,1]],dtype=torch.float32)\n",
    "input = torch.reshape(input,(-1,1,5,5))\n",
    "\n",
    "#ceil_mode=True,向上取整(后面取不完的矩阵保留/不保留)\n",
    "#kenel_size=2,stride=2,就是2*2的矩阵,每次移动2个单位,不需要自己写矩阵\n",
    "\n",
    "class max_pooling(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(max_pooling,self).__init__()\n",
    "        self.max_pool = nn.MaxPool2d(kernel_size=3,ceil_mode=True)\n",
    "    def forward(self,x):\n",
    "        x = self.max_pool(x)\n",
    "        return x\n",
    "\n",
    "model = max_pooling()\n",
    "output = model(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "最大池化的作用：保留数据的特征并且减小数据量 1080p -> 720p 压缩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#直观查看maxpooling的效果\n",
    "\n",
    "#提数据 先提成dataset再转换成dataLoader\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data2',train=False,download=True,transform=torchvision.transforms.ToTensor())\n",
    "dataloader = DataLoader(dataset,batch_size=64)\n",
    "\n",
    "writer = SummaryWriter('max_pooling')\n",
    "#把数据填进网络,并在tensorboard中查看结果\n",
    "#30 = 32 - 3 + 1\n",
    "step = 0\n",
    "model = max_pooling()\n",
    "for data in dataloader:\n",
    "    img,target = data\n",
    "    # [64, 3, 32, 32] -> [64, 6, 30, 30]\n",
    "    output = model(img)\n",
    "    #要在tensorboard中查看结果需要channel不大于3\n",
    "    writer.add_images('max_pooling',output,step)\n",
    "    step += 1\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 非线性激活"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7311, 0.3775],\n",
      "        [0.2689, 0.9526]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "input = torch.tensor([[1,-0.5],[-1,3]])\n",
    "\n",
    "class sigmoid(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(sigmoid,self).__init__()\n",
    "    def forward(self,x):\n",
    "        return nn.functional.sigmoid(x)\n",
    "\n",
    "model = sigmoid()\n",
    "output = model(input)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = torchvision.datasets.CIFAR10(root='./data2',train=False,download=True,transform=torchvision.transforms.ToTensor())\n",
    "dataloader = DataLoader(dataset,batch_size=64)\n",
    "\n",
    "writer = SummaryWriter('sigmoid')\n",
    "#把数据填进网络,并在tensorboard中查看结果\n",
    "step = 0\n",
    "model = sigmoid()\n",
    "for data in dataloader:\n",
    "    img,target = data\n",
    "    writer.add_images('input',img,step)\n",
    "    output = model(img)\n",
    "    #要在tensorboard中查看结果需要channel不大于3\n",
    "    writer.add_images('output',output,step)\n",
    "    step += 1\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  线性层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 3, 32, 32])\n",
      "torch.Size([64, 3072])\n",
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision \n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data2',train=False,download=True,transform=torchvision.transforms.ToTensor())\n",
    "dataloader = DataLoader(dataset,batch_size=64)\n",
    "\n",
    "writer = SummaryWriter('linear')\n",
    "\n",
    "class linear(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(linear,self).__init__()\n",
    "        #channel*height*width\n",
    "        self.linear = nn.Linear(3*32*32,10)\n",
    "    def forward(self,x):\n",
    "        return self.linear(x)\n",
    "\n",
    "model = linear()\n",
    "step = 0\n",
    "for data in dataloader:\n",
    "    img,target = data\n",
    "    print(img.shape)\n",
    "    img = torch.flatten(img,start_dim=1)\n",
    "    print(img.shape)\n",
    "    output = model(img)\n",
    "    print(output.shape)\n",
    "    step += 1\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([64, 10])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import Conv2d\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "class ep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ep,self).__init__() #调用父类的构造函数\n",
    "        self.model1 = nn.Sequential(\n",
    "            #conv中的padding通过计算得出\n",
    "            nn.Conv2d(3, 32, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            #linear的输入输出都是一维\n",
    "            nn.Linear(64*4*4, 64),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.model1(x)\n",
    "        return x\n",
    "\n",
    "model = ep()\n",
    "input = torch.ones((64,3,32,32))\n",
    "print(model(input).shape)\n",
    "\n",
    "writer = SummaryWriter('logs_seq')\n",
    "#计算图\n",
    "writer.add_graph(model,input)\n",
    "writer.close()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 损失函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.6667)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "input = torch.tensor([1,2,3],dtype=torch.float32)\n",
    "target = torch.tensor([1,2,5],dtype=torch.float32)\n",
    "\n",
    "#为什么要reshape,因为输入的数据是[3],而loss函数需要的是[1,3] 1是batch_size\n",
    "#主要关注input和target的shape\n",
    "input = torch.reshape(input,(1,1,1,3))\n",
    "target = torch.reshape(target,(1,1,1,3))\n",
    "\n",
    "loss = nn.L1Loss()\n",
    "print(loss(input,target))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "神经网络类:初始化与前向传播，计算损失函数和梯度反向传播都写在外面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3211, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data2',train=False,download=True,transform=torchvision.transforms.ToTensor())\n",
    "dataloader = DataLoader(dataset,batch_size=1)\n",
    "class ep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ep,self).__init__() #调用父类的构造函数\n",
    "        self.model1 = nn.Sequential(\n",
    "            #conv中的padding通过计算得出\n",
    "            nn.Conv2d(3, 32, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            #linear的输入输出都是一维\n",
    "            nn.Linear(64*4*4, 64),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.model1(x)\n",
    "        return x\n",
    "#nn.Module与nn.Loss都要先进行初始化\n",
    "model = ep()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "for data in dataloader:\n",
    "    img,target = data\n",
    "    output = model(img)\n",
    "    #计算损失\n",
    "    loss_value = loss(output,target)\n",
    "    #反向传播写在这里\n",
    "    loss_value.backward()\n",
    "    print(loss_value)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 优化器\n",
    "\n",
    "torch.optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18706.792583032046\n",
      "16125.594056693866\n",
      "15516.942673036378\n",
      "16073.606622038087\n",
      "17985.536766862962\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m在当前单元格或上一个单元格中执行代码时 Kernel 崩溃。\n",
      "\u001b[1;31m请查看单元格中的代码，以确定故障的可能原因。\n",
      "\u001b[1;31m单击<a href='https://aka.ms/vscodeJupyterKernelCrash'>此处</a>了解详细信息。\n",
      "\u001b[1;31m有关更多详细信息，请查看 Jupyter <a href='command:jupyter.viewOutput'>log</a>。"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data2',train=False,download=True,transform=torchvision.transforms.ToTensor())\n",
    "dataloader = DataLoader(dataset,batch_size=1)\n",
    "class ep(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ep,self).__init__() #调用父类的构造函数\n",
    "        self.model1 = nn.Sequential(\n",
    "            #conv中的padding通过计算得出\n",
    "            nn.Conv2d(3, 32, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 32, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Conv2d(32, 64, 5, padding=2),\n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Flatten(),\n",
    "            #linear的输入输出都是一维\n",
    "            nn.Linear(64*4*4, 64),\n",
    "            nn.Linear(64, 10)\n",
    "        )\n",
    "    def forward(self,x):\n",
    "        x = self.model1(x)\n",
    "        return x\n",
    "#先进行初始化 模型/损失函数/优化器\n",
    "model = ep()\n",
    "loss = nn.CrossEntropyLoss()\n",
    "optim = torch.optim.SGD(model.parameters(),lr=0.01)\n",
    "for epoch in range(5):\n",
    "    running_loss = 0.0\n",
    "    for data in dataloader:\n",
    "        img,target = data\n",
    "        output = model(img)\n",
    "        #计算损失\n",
    "        loss_value = loss(output,target)\n",
    "        #梯度清零\n",
    "        optim.zero_grad()\n",
    "        #反向传播求梯度\n",
    "        loss_value.backward()\n",
    "        #更新参数\n",
    "        optim.step()\n",
    "        running_loss += loss_value.item()\n",
    "    print(running_loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
