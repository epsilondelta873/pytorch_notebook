{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pytorch安装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "查询package里的函数以及函数如何使用"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Any',\n",
       " 'BFloat16Storage',\n",
       " 'BFloat16Tensor',\n",
       " 'BoolStorage',\n",
       " 'BoolTensor',\n",
       " 'ByteStorage',\n",
       " 'ByteTensor',\n",
       " 'CUDAGraph',\n",
       " 'CUDAPluggableAllocator',\n",
       " 'Callable',\n",
       " 'CharStorage',\n",
       " 'CharTensor',\n",
       " 'ComplexDoubleStorage',\n",
       " 'ComplexFloatStorage',\n",
       " 'CudaError',\n",
       " 'DeferredCudaCallError',\n",
       " 'Device',\n",
       " 'DoubleStorage',\n",
       " 'DoubleTensor',\n",
       " 'Event',\n",
       " 'ExternalStream',\n",
       " 'FloatStorage',\n",
       " 'FloatTensor',\n",
       " 'HalfStorage',\n",
       " 'HalfTensor',\n",
       " 'IntStorage',\n",
       " 'IntTensor',\n",
       " 'List',\n",
       " 'LongStorage',\n",
       " 'LongTensor',\n",
       " 'MemPool',\n",
       " 'MemPoolContext',\n",
       " 'Optional',\n",
       " 'OutOfMemoryError',\n",
       " 'ShortStorage',\n",
       " 'ShortTensor',\n",
       " 'Stream',\n",
       " 'StreamContext',\n",
       " 'Tuple',\n",
       " 'Union',\n",
       " '_CudaBase',\n",
       " '_CudaDeviceProperties',\n",
       " '_DeviceGuard',\n",
       " '_HAS_PYNVML',\n",
       " '_LazySeedTracker',\n",
       " '_PYNVML_ERR',\n",
       " '_WrappedTritonKernel',\n",
       " '__all__',\n",
       " '__annotations__',\n",
       " '__builtins__',\n",
       " '__cached__',\n",
       " '__doc__',\n",
       " '__file__',\n",
       " '__loader__',\n",
       " '__name__',\n",
       " '__package__',\n",
       " '__path__',\n",
       " '__spec__',\n",
       " '_cached_device_count',\n",
       " '_check_bf16_tensor_supported',\n",
       " '_check_capability',\n",
       " '_check_cubins',\n",
       " '_cudart',\n",
       " '_device',\n",
       " '_device_count_amdsmi',\n",
       " '_device_count_nvml',\n",
       " '_device_t',\n",
       " '_dummy_type',\n",
       " '_exchange_device',\n",
       " '_extract_arch_version',\n",
       " '_get_amdsmi_clock_rate',\n",
       " '_get_amdsmi_device_index',\n",
       " '_get_amdsmi_device_memory_used',\n",
       " '_get_amdsmi_handler',\n",
       " '_get_amdsmi_memory_usage',\n",
       " '_get_amdsmi_power_draw',\n",
       " '_get_amdsmi_temperature',\n",
       " '_get_amdsmi_utilization',\n",
       " '_get_device',\n",
       " '_get_device_index',\n",
       " '_get_generator',\n",
       " '_get_nvml_device_index',\n",
       " '_get_pynvml_handler',\n",
       " '_get_rng_state_offset',\n",
       " '_initialization_lock',\n",
       " '_initialized',\n",
       " '_is_compiled',\n",
       " '_is_in_bad_fork',\n",
       " '_lazy_call',\n",
       " '_lazy_init',\n",
       " '_lazy_new',\n",
       " '_lazy_seed_tracker',\n",
       " '_maybe_exchange_device',\n",
       " '_memory_viz',\n",
       " '_nvml_based_avail',\n",
       " '_parse_visible_devices',\n",
       " '_queued_calls',\n",
       " '_raw_device_count_amdsmi',\n",
       " '_raw_device_count_nvml',\n",
       " '_raw_device_uuid_amdsmi',\n",
       " '_raw_device_uuid_nvml',\n",
       " '_register_triton_kernels',\n",
       " '_set_rng_state_offset',\n",
       " '_set_stream_by_id',\n",
       " '_sleep',\n",
       " '_tls',\n",
       " '_transform_uuid_to_ordinals',\n",
       " '_utils',\n",
       " '_warn_typed_storage_removal',\n",
       " 'amp',\n",
       " 'caching_allocator_alloc',\n",
       " 'caching_allocator_delete',\n",
       " 'caching_allocator_enable',\n",
       " 'can_device_access_peer',\n",
       " 'cast',\n",
       " 'change_current_allocator',\n",
       " 'check_error',\n",
       " 'classproperty',\n",
       " 'clock_rate',\n",
       " 'cudaStatus',\n",
       " 'cudart',\n",
       " 'current_blas_handle',\n",
       " 'current_device',\n",
       " 'current_stream',\n",
       " 'default_generators',\n",
       " 'default_stream',\n",
       " 'device',\n",
       " 'device_count',\n",
       " 'device_memory_used',\n",
       " 'device_of',\n",
       " 'empty_cache',\n",
       " 'gds',\n",
       " 'get_allocator_backend',\n",
       " 'get_arch_list',\n",
       " 'get_device_capability',\n",
       " 'get_device_name',\n",
       " 'get_device_properties',\n",
       " 'get_gencode_flags',\n",
       " 'get_per_process_memory_fraction',\n",
       " 'get_rng_state',\n",
       " 'get_rng_state_all',\n",
       " 'get_sync_debug_mode',\n",
       " 'graph',\n",
       " 'graph_pool_handle',\n",
       " 'graphs',\n",
       " 'has_half',\n",
       " 'has_magma',\n",
       " 'importlib',\n",
       " 'init',\n",
       " 'initial_seed',\n",
       " 'ipc_collect',\n",
       " 'is_available',\n",
       " 'is_bf16_supported',\n",
       " 'is_current_stream_capturing',\n",
       " 'is_initialized',\n",
       " 'jiterator',\n",
       " 'list_gpu_processes',\n",
       " 'lru_cache',\n",
       " 'make_graphed_callables',\n",
       " 'manual_seed',\n",
       " 'manual_seed_all',\n",
       " 'max_memory_allocated',\n",
       " 'max_memory_cached',\n",
       " 'max_memory_reserved',\n",
       " 'mem_get_info',\n",
       " 'memory',\n",
       " 'memory_allocated',\n",
       " 'memory_cached',\n",
       " 'memory_reserved',\n",
       " 'memory_snapshot',\n",
       " 'memory_stats',\n",
       " 'memory_stats_as_nested_dict',\n",
       " 'memory_summary',\n",
       " 'memory_usage',\n",
       " 'nccl',\n",
       " 'nvtx',\n",
       " 'os',\n",
       " 'power_draw',\n",
       " 'profiler',\n",
       " 'random',\n",
       " 'reset_accumulated_memory_stats',\n",
       " 'reset_max_memory_allocated',\n",
       " 'reset_max_memory_cached',\n",
       " 'reset_peak_memory_stats',\n",
       " 'seed',\n",
       " 'seed_all',\n",
       " 'set_device',\n",
       " 'set_per_process_memory_fraction',\n",
       " 'set_rng_state',\n",
       " 'set_rng_state_all',\n",
       " 'set_stream',\n",
       " 'set_sync_debug_mode',\n",
       " 'sparse',\n",
       " 'stream',\n",
       " 'streams',\n",
       " 'synchronize',\n",
       " 'temperature',\n",
       " 'threading',\n",
       " 'torch',\n",
       " 'traceback',\n",
       " 'tunable',\n",
       " 'use_mem_pool',\n",
       " 'utilization',\n",
       " 'warnings']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(torch.cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function is_available in module torch.cuda:\n",
      "\n",
      "is_available() -> bool\n",
      "    Return a bool indicating if CUDA is currently available.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#查函数不要加括号\n",
    "help(torch.cuda.is_available)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 读取数据:dataset与dataloader\n",
    "\n",
    "dataset:提供一种方式获取数据及其label\n",
    "\n",
    "dataloader：为后面的网络提供不同的数据形式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "from PIL import Image\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#自定义Dataset类用于读取图片数据\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self,root_dir,label_dir):\n",
    "        self.root_dir = root_dir #数据集根目录\n",
    "        self.label_dir = label_dir #标签目录 ants or bees\n",
    "        self.path = os.path.join(self.root_dir,self.label_dir) #拼接路径\n",
    "        self.img_path = os.listdir(self.path) #读取路径下的所有文件名称\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        img_name = self.img_path[idx] #获取图片名称\n",
    "        img_path = os.path.join(self.path,img_name) #拼接图片路径\n",
    "        img = Image.open(img_path) #读取图片\n",
    "        label = self.label_dir\n",
    "        return img,label\n",
    "    def __len__(self):\n",
    "        return len(self.img_path) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#读取蚂蚁数据集\n",
    "root_dir = r'F:\\RUC\\pytorch\\数据集\\hymenoptera_data\\train'\n",
    "label_dir = 'ants'\n",
    "ants_dataset = MyDataset(root_dir,label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "124"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#打开图片\n",
    "img,label = ants_dataset.__getitem__(0)\n",
    "#或者使用:\n",
    "#img,label = ants_dataset[0]\n",
    "img.show()\n",
    "\n",
    "#查看数据集大小\n",
    "ants_dataset.__len__()\n",
    "#或者使用:\n",
    "#len(ants_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r'F:\\RUC\\pytorch\\数据集\\hymenoptera_data\\train'\n",
    "label_dir = 'bees'\n",
    "bees_dataset = MyDataset(root_dir,label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#合并数据集\n",
    "train_dataset = ants_dataset + bees_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#查看合并数数据集的信息\n",
    "img,label = train_dataset.__getitem__(125)\n",
    "img.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#如果是图片+标签的形式 如何读取数据\n",
    "class MyDataset2(Dataset):\n",
    "    def __init__(self,root_dir,image_dir,label_dir):\n",
    "        self.root_dir = root_dir #数据集根目录\n",
    "        self.image_dir = image_dir #图片目录\n",
    "        self.label_dir = label_dir #标签目录\n",
    "        self.image_path = os.path.join(self.root_dir,self.image_dir) #拼接路径并读取\n",
    "        self.label_path = os.path.join(self.root_dir,self.label_dir)\n",
    "        self.image_list = os.listdir(self.image_path)\n",
    "        self.label_list = os.listdir(self.label_path)\n",
    "        # 因为label 和 Image文件名相同，进行一样的排序，可以保证取出的数据和label是一一对应的\n",
    "        self.image_list.sort()\n",
    "        self.label_list.sort()\n",
    " \n",
    "    def __getitem__(self,idx):\n",
    "        #图片、标签名称/路径\n",
    "        img_name = self.image_list[idx]\n",
    "        label_name = self.label_list[idx]\n",
    "        img_item_path = os.path.join(self.root_dir, self.image_dir, img_name)\n",
    "        label_item_path = os.path.join(self.root_dir, self.label_dir, label_name)\n",
    "        #读取图片、标签\n",
    "        img = Image.open(img_item_path)\n",
    "\n",
    "        with open(label_item_path, 'r') as f:\n",
    "            label = f.readline()\n",
    "\n",
    "        # img = np.array(img)\n",
    "        #?这里为什么要转换为tensor\n",
    "        #img = self.transform(img) 暂时先不用transform\n",
    "        sample = {'img': img, 'label': label}\n",
    "        return sample\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.label_list) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r'F:\\RUC\\pytorch\\数据集\\练手数据集\\train'\n",
    "image_dir = 'ants_image'\n",
    "label_dir = 'ants_label'\n",
    "\n",
    "ants_dataset = MyDataset2(root_dir,image_dir,label_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#打开图片\n",
    "ants_dataset[0]['img'].show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorboard的使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SummaryWriter类是 PyTorch 中 torch.utils.tensorboard 模块提供的一个重要工具，主要用于将训练过程中的各种数据（如损失值、准确率、图像等）写入 TensorBoard 可以读取的日志文件，方便用户通过 TensorBoard 可视化工具直观地观察和分析模型的训练过程和性能。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#创建类\n",
    "writer = SummaryWriter('logs')\n",
    "\n",
    "for i in range(100):\n",
    "    writer.add_scalar('y = 2x',2*i,i)\n",
    "#关闭类\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512, 768, 3)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "#打开一张图片然后转成numpy类型\n",
    "image_path = r'F:\\RUC\\pytorch\\数据集\\练手数据集\\train\\ants_image\\0013035.jpg'\n",
    "image_PIL = Image.open(image_path)\n",
    "image_array = np.array(image_PIL)\n",
    "#查看array的通道数\n",
    "print(image_array.shape)\n",
    "\n",
    "#创建类\n",
    "writer = SummaryWriter('logs')\n",
    "#转换成numpy数组后需要修改dataformats,因为和默认的不一样\n",
    "writer.add_image('test',image_array,1,dataformats='HWC')\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.3608, 0.3686, 0.3686,  ..., 0.4039, 0.4000, 0.4078],\n",
       "         [0.3569, 0.3647, 0.3686,  ..., 0.4078, 0.4078, 0.4157],\n",
       "         [0.3686, 0.3608, 0.3569,  ..., 0.4039, 0.4118, 0.4157],\n",
       "         ...,\n",
       "         [0.3725, 0.3686, 0.3686,  ..., 0.8902, 0.8863, 0.8824],\n",
       "         [0.3608, 0.3608, 0.3647,  ..., 0.8941, 0.8902, 0.8902],\n",
       "         [0.3608, 0.3608, 0.3647,  ..., 0.8941, 0.8902, 0.8863]],\n",
       "\n",
       "        [[0.5686, 0.5725, 0.5725,  ..., 0.6235, 0.6196, 0.6275],\n",
       "         [0.5647, 0.5686, 0.5725,  ..., 0.6275, 0.6275, 0.6353],\n",
       "         [0.5765, 0.5647, 0.5608,  ..., 0.6314, 0.6392, 0.6431],\n",
       "         ...,\n",
       "         [0.5922, 0.5882, 0.5843,  ..., 0.9176, 0.9137, 0.9098],\n",
       "         [0.5765, 0.5765, 0.5843,  ..., 0.9137, 0.9098, 0.9098],\n",
       "         [0.5765, 0.5765, 0.5843,  ..., 0.9137, 0.9098, 0.9059]],\n",
       "\n",
       "        [[0.0039, 0.0039, 0.0039,  ..., 0.0000, 0.0000, 0.0000],\n",
       "         [0.0000, 0.0039, 0.0039,  ..., 0.0039, 0.0000, 0.0039],\n",
       "         [0.0118, 0.0000, 0.0000,  ..., 0.0039, 0.0039, 0.0078],\n",
       "         ...,\n",
       "         [0.0078, 0.0039, 0.0118,  ..., 0.8902, 0.8863, 0.8824],\n",
       "         [0.0039, 0.0039, 0.0000,  ..., 0.8863, 0.8824, 0.8863],\n",
       "         [0.0039, 0.0039, 0.0000,  ..., 0.8863, 0.8863, 0.8824]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#读取一个图片\n",
    "img_path = r'F:\\RUC\\pytorch\\数据集\\练手数据集\\train\\ants_image\\541630764_dbd285d63c.jpg'\n",
    "img = Image.open(img_path)\n",
    "\n",
    "#定义totensor对象 转换图片\n",
    "tensor_trans = transforms.ToTensor()\n",
    "tensor_img = tensor_trans(img)\n",
    "\n",
    "#查看tensor\n",
    "tensor_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#常见的transforms\n",
    "\n",
    "#打开一张图片\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "img = Image.open(r'F:\\RUC\\pytorch\\数据集\\练手数据集\\train\\ants_image\\2288481644_83ff7e4572.jpg')\n",
    "                 \n",
    "#compose\n",
    "#transforms.Compose将多个transforms方法组合起来使用\n",
    "#比如将图片先resize到256*256，然后随机裁剪到224*224，最后转换为tensor\n",
    "\n",
    "\n",
    "#totensor\n",
    "#将PIL Image或者 ndarray 转换为tensor，并且归一化到[0-1.0]之间\n",
    "tensor_trans = transforms.ToTensor()\n",
    "tensor_img = tensor_trans(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.2784)\n",
      "tensor(-0.4431)\n"
     ]
    }
   ],
   "source": [
    "#normalize\n",
    "#将每个信道的数据标准化到设定的均值和标准差\n",
    "#标准化前\n",
    "print(tensor_img[0][0][0])\n",
    "trans_norm = transforms.Normalize(mean=[0.5,0.5,0.5],std=[0.5,0.5,0.5])\n",
    "img_norm = trans_norm(tensor_img)\n",
    "#标准化后\n",
    "print(img_norm[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(500, 500)\n",
      "(256, 256)\n"
     ]
    }
   ],
   "source": [
    "#resize\n",
    "#调整图片大小\n",
    "print(img.size)\n",
    "trans_resize = transforms.Resize((256,256))\n",
    "img_resize = trans_resize(img)\n",
    "print(img_resize.size)\n",
    "#如果要在tensorboard中显示，需要转换成tensor  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#randomcrop\n",
    "#随机裁剪图片\n",
    "trans_random = transforms.RandomCrop(256)\n",
    "trans_compose = transforms.Compose([trans_random,tensor_trans])\n",
    "for i in range(10):\n",
    "    img_crop = trans_compose(img)\n",
    "    writer.add_image('randomcrop',img_crop,i)\n",
    "#在tensorboard中查看各步骤结果\n",
    "writer.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frog\n"
     ]
    }
   ],
   "source": [
    "#下载torchvision中的数据集且不进行transform操作\n",
    "import torchvision\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data',train=True,download=True)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data',train=False,download=True)\n",
    "\n",
    "#查看原始数据集\n",
    "img,target = train_set[0]\n",
    "img.show()\n",
    "#查看标签\n",
    "print(train_set.classes[target])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#下载torchvision中的数据集且进行transform操作\n",
    "#用compose定义transform\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "train_set = torchvision.datasets.CIFAR10(root='./data',train=True,download=True,transform=transform)\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data',train=False,download=True,transform=transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 32, 32])\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#从torchvision中加载数据集\n",
    "from torch.utils.data import DataLoader\n",
    "transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])\n",
    "test_set = torchvision.datasets.CIFAR10(root='./data',train=False,download=True,transform=transform)\n",
    "\n",
    "test_loader = DataLoader(test_set,batch_size=64,shuffle=True,num_workers=0,drop_last=True)\n",
    "#batch_size:每次读取并合并的数据量,然后将所有数据按照该方式划分成n//4批\n",
    "\n",
    "#查看原始数据集的第一张图片及标签\n",
    "img,target = test_set[0]\n",
    "print(img.shape)\n",
    "print(target)\n",
    "\n",
    "#查看dataloader中的数据\n",
    "writer = SummaryWriter('dataloader')\n",
    "step = 0\n",
    "#epoch是指遍历整个数据集的次数\n",
    "for epoch in range(2):\n",
    "    for data in test_loader:\n",
    "        img,target = data\n",
    "        #print(img.shape)\n",
    "        #print(target)\n",
    "        writer.add_images('test_drop',img,step)\n",
    "        step += 1\n",
    "writer.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
