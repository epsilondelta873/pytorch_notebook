# 数据提取与加载

## Dataset

使用dataset可以从torch的模块中提取数据，也可以自己定义一个dataset类读取本地数据和标签

1.自定义dataset读取本地数据：初始化（设定路径），get_item（提取单个数据），len（计算数据集长度）

```python
class MyDataset2(Dataset):
    #定义路径 将路径拼在一起 获取文件名list
    def __init__(self,root_dir,image_dir,label_dir):
        self.root_dir = root_dir #数据集根目录
        self.image_dir = image_dir #图片目录
        self.label_dir = label_dir #标签目录
        self.image_path = os.path.join(self.root_dir,self.image_dir) #拼接路径并读取
        self.label_path = os.path.join(self.root_dir,self.label_dir)
        self.image_list = os.listdir(self.image_path)
        self.label_list = os.listdir(self.label_path)
        # 因为label 和 Image文件名相同，进行一样的排序，可以保证取出的数据和label是一一对应的
        self.image_list.sort()
        self.label_list.sort()
    
    #提取出一个具体的item
    def __getitem__(self,idx):
        #图片、标签名称/路径
        img_name = self.image_list[idx]
        label_name = self.label_list[idx]
        img_item_path = os.path.join(self.root_dir, self.image_dir, img_name)
        label_item_path = os.path.join(self.root_dir, self.label_dir, label_name)
        #读取图片、标签
        img = Image.open(img_item_path)

        with open(label_item_path, 'r') as f:
            label = f.readline()

        # img = np.array(img)
        #如果需要可以将数据进行变换后输出
        #img = self.transform(img) 暂时先不用transform
        sample = {'img': img, 'label': label}
        return sample

    #返回数据集长度
    def __len__(self):
        return len(self.label_list) 
```

提取数据示范：

```python
root_dir = r'F:\RUC\pytorch\数据集\练手数据集\train'
image_dir = 'ants_image'
label_dir = 'ants_label'

ants_dataset = MyDataset2(root_dir,image_dir,label_dir)

#打开图片
ants_dataset[0]['img'].show()
```

2.使用torchvision中的dataset类提取开发者提供的数据集

```python
#设定数据变换方式
transform = transforms.Compose([transforms.ToTensor()])
#root为将数据保存的路径 
#train为提取的是训练集还是测试集
#download为是否下载该数据集 一般选True
#transform为需要对数据进行的变换
test_set = torchvision.datasets.CIFAR10(root='./data',train=False,download=True,transform=transform)
```

## Dataloader

从dataset提取数据到神经网络，打包成batch的形式传入

设置多个epoch可以使得不同的样本合成一个批次(shuffle = True)

同时要注意使用tensorbord查看数据的时候SummaryWriter('dataloader')可以不用写绝对路径和提前创建，会自动在工作路径创建，但在terminal执行时最好引用绝对路径不然系统找不到(或者使用cd切换)

```conda
cd F:\RUC\pytorch
tensorboard --logdir='dataloader'
```

```python
#从torchvision中加载数据集
from torch.utils.data import DataLoader
transform = transforms.Compose([transforms.ToTensor(),transforms.Normalize((0.5,0.5,0.5),(0.5,0.5,0.5))])
test_set = torchvision.datasets.CIFAR10(root='./data',train=False,download=True,transform=transform)

test_loader = DataLoader(test_set,batch_size=64,shuffle=True,num_workers=0,drop_last=True)
#batch_size:每次读取并合并的数据量,然后将所有数据按照该方式划分成n//4批

#查看原始数据集的第一张图片及标签
img,target = test_set[0]
print(img.shape)
print(target)

#查看dataloader中的数据
writer = SummaryWriter('dataloader')
step = 0
#epoch是指遍历整个数据集的次数
for epoch in range(2):
    for data in test_loader:
        img,target = data
        #print(img.shape)
        #print(target)
        writer.add_images('test_drop',img,step)
        step += 1
writer.close()
```
